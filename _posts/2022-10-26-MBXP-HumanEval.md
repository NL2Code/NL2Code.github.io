---
title: MBXP-HumanEval
author: coder
date: 2022-10-26 00:00:00 +0800
categories: [arxiv]
tags: [benchmarks]
math: true
---

- ğŸ—‚ï¸Benchmark Name: [MBXP-HumanEval](https://arxiv.org/pdf/2210.14868.pdf)
- ğŸ“šPublisher: `Arxiv`
- ğŸ Author Affiliation: `AWS AI Labs`
- ğŸ”—URL: [https://github.com/amazon-research/mbxp-exec-eval](https://github.com/amazon-research/mbxp-exec-eval)
- Number of Instances: `164` per programming language
- Problem Description's Natural Language: `English`
- Code Solution's Programming Language: `Python`, `Java`, `JavaScript`, `Kotlin`, `Perl`, `PHP`, `Ruby`, `Scala`, `Swift`
- Data Statistics
  + Test Case: âœ…
  + Average Number of Test Cases: `7.8`
  + Average Number of Characters in Problem Description: `825.6`
  + Average Number of Lines in Problem Description: `30.0`
  + Average Number of Characters in Code Solution: /
  + Average Number of Lines in Code Solution: /
- Scenario: `Multilingual`
